#!/bin/bash
#note: bash has to support array, in order to run this code, bash_version 2.x onwards does.
input="parameter_space.bash"
. ./collectdata_config.bash
. ./collectdata_function.bash
# cleaning
datesuffix=$(date +"%y%m%d_%H%M%S")
id=$datesuffix
echo "Deleting any detector log files from con0:massive"
ssh con0 "rm massive/detector_log*"
cp all_config all_config"$datesuffix"
cp conflict.txt conflict"$datesuffix".txt
# clean dataplane and host data
bash collectdata_stop_and_clean.bash "$numsw" "$numep"
exit_code=$?
[ $exit_code -ne 0 ] && echo "stop and clean error!, exit code $exit_code" | tee -a conflict.txt && exit 1
> all_config
> conflict.txt
rm temp.txt 

sed -n 1,10p parameter_space.bash > all_config

echo "$id" >> all_config
echo "$id" > conflict.txt

i=1
while IFS= read -r line
do
  if [ -z "$line" ]; then
      break
  fi
  echo "line $i: $line" #| awk '$1=="APPS" {print $1 " " $2 " " $3}'
  if [ $i -eq 1 ]; then #process APPS
	apps=($line) #initiate an array
	for (( index=0; index<${#apps[@]}; index++ ))
	do
	  echo "Apps for this experiment are: ${apps[$index]}"
	done
  fi
  if [ $i -eq 2 ]; then #process APPCONF
	appconf=($line)
	for (( index=0; index<${#appconf[@]}; index++ ))
	do
	  echo "Number of configurations per app:${appconf[$index]}"
	done
  fi
  if [ $i -eq 3 ]; then #process TRANS, transport type
	trans=($line)
	for (( index=0; index<${#trans[@]}; index++ ))
	do
	  echo "Generated transport types: ${trans[$index]}"
	done
  fi
  if [ $i -eq 4 ]; then #process TARGETSW
	IFS=':' read -ra ts <<< "$line"
  echo "Target switches of apps:"
	for j in "${ts[@]}"; do echo "$j"; done #ts=target switch
  fi
  if [ $i -eq 5 ]; then #process EPTRAFPROF
	trafprof=($line)
	for (( index=0; index<${#trafprof[@]}; index++ ))
	do
	  echo "Generated traffic profiles: ${trafprof[$index]}"
	done
  fi
  if [ $i -eq 6 ]; then #process NUMSW
	numsw=$line
	echo "number of switches = $numsw"
  fi
  if [ $i -eq 7 ]; then #process NUMEP
	numep=$line
	echo "number of end-points = $numep"
  fi
  if [ $i -eq 8 ]; then #process EPCOMBI
	IFS=':' read -ra comb <<< $line
  echo "Endpoint combination is:"
	for j in "${comb[@]}"; do echo "$j"; done #comb=endpoint combination
  fi
  if [ $i -eq 9 ]; then #process topology name
	id="${line}_${id}"
	echo "Id for this experiment is ${id}"
  fi
  (( i++ ))
done < "$input"

echo "remove all router*_dumpflows_* from all routers/switches to prepare fresh data for the dataset"
for i in $(seq 1 "$numsw"); do ssh -n router"$i" "sh -c 'rm -f router$i\_dumpflows*'"; done
echo "remove all tmp* files from all end-points to have fresh data for comparison between expected and observed network behaviour at end-points"
for i in $(seq 1 "$numep"); do ssh -n pc"$i" "sh -c 'rm -f tmp*'"; done
echo "remove detector_log in the controller if any"
ssh -n con0 "sh -c 'cd $APPDIR; rm -f detector_log_*'"

echo "Deploy each application in isolation to derive the expected network behaviour."
for (( i_a=0; i_a<${#apps[@]}; i_a++ )) #index_application
do
  echo "${apps[$i_a]}"
  file=${apps[$i_a]}_config_global
  echo "#config: ${appconf[$i_a]}"
  for (( c=1; c<=${appconf[$i_a]};c++ )); do #config
    echo $c
    echo "2 #priority" > $file
    echo "${ts[$i_a]} #target switches" >> $file
    echo "$c #app config" >> $file
    echo >> $file
    echo "[global] #generated by the script from outer machine" >> $file
    echo "content of $file"
    cat "$file"    
    scp "$file" con0:"$APPDIR" #con0 is the hostname of the controller0
    # adapt the local config file of the control app (CA): each CA has in *massive* directory of con0 the local1/2/3... file, choose one to be the *local*.
    ssh -n con0 "sh -c 'cd $APPDIR; cp ${apps[$i_a]}_config_local$c ${apps[$i_a]}_config_local; git add ${apps[$i_a]}.py ${apps[$i_a]}_config_local$c'"

    echo >> all_config
    echo ${apps[$i_a]}_config_local$c >> all_config
    ssh -n con0 "sh -c 'cd $APPDIR; cat ${apps[$i_a]}_config_local$c'" >> all_config
    #run controller
    #generate traffic at end-point
    #TODO: loop through end-point traffic profile and end-point combination dimensions
    #dump traffic in involved end-points and routers, observe the path
    #stop end-point, stop controller
    # control the detector_log_filename in the controller according to the experiment point, 
    # these files are later collected in the dataset
    ssh -n con0 "sh -c 'cd $APPDIR; echo detector_log_${apps[$i_a]}_$c > detector_log_filename'" 
    bash collectdata_controller.bash "${apps[$i_a]}"
    exit_code=$?
    [ $exit_code -ne 0 ] && echo "Controller is not running, exit code $exit_code" | tee -a conflict.txt && exit 1
    bash collectdata_dataplane.bash "${apps[$i_a]}_$c" "${comb[0]}" "${comb[1]}" "$numsw" "iso" # $5 is a dummy variable to check if this is an isolated run for the firewall
    bash collectdata_stop_and_clean.bash "$numsw" "$numep"
    exit_code=$?
    [ $exit_code -ne 0 ] && echo "stop and clean error!, exit code $exit_code" | tee -a conflict.txt && exit 1
  done
done #end deploying in isolation

ignoreErrors=$(grep -c '"evaluationRun": true' parameter_space.json)
if [ $ignoreErrors -lt 1 ]; then
  p=$(grep -c "error with nc" conflict.txt)
  if [ $p -gt 0 ]; then
    echo "There is problem while deploying control apps in isolation, check conflict.txt, exit now!"
    echo "Note that: the destination list in parameter_space.bash has to cover all the end-points in local config of all control apps."
    mkdir -p topology_errors
    cp conflict.txt topology_errors/"$id.txt"
    cp parameter_space.json topology_errors/"$id.json"
    exit 1
  fi
else
  echo "This is set as evaluation run, any failed connections will be ignored for isolated app deployments!"
fi

# git commit all changes in the con0:$APPDIR, get the commit id and store the commit id in the all_config file, so that the one_app.bash and one_point.bash can restore all the configuration from the dataset
ssh -n con0 "sh -c 'cd $APPDIR; git commit -am \".\"; git push'"
echo -n "gitcommitid=" >> all_config
ssh -n con0 "sh -c 'cd $APPDIR; git log -n 1 --format=format:\"%H\" '" >> all_config #store the commit hash in all_config.
echo >> all_config
#storing app:
(cd dataset/massive || echo "Could not cd to dataset/massive"; git pull)

python choose_app.py ${#apps[@]} > app_choice

#priority is dependent on each combination of app choice, e.g., if there're two
#apps, priority will be 2 2, 2 3, 3 2. If there're 3 apps, it is 2 2 2, 2 2 3...
#target switches is stored above

#loop through parameter space:
#choose application combination:
point=1
while IFS= read -r line; do
  ch=($line) #choice
  tmp_cfg_arg="" #temp_config_argument
  for (( index=0; index<${#ch[@]}; index++ )); do
    echo "${apps[${ch[$index]}]}: ${appconf[${ch[$index]}]}"
    tmp_cfg_arg="$tmp_cfg_arg ${appconf[${ch[$index]}]}" 
  done
  python generate_config.py $tmp_cfg_arg > app_config
  echo "All app config combinations:"
  cat app_config
  #now, having the app_config dimension, loop through it again.
  while IFS= read -r line_appcfg; do
    conf=($line_appcfg)
    [ ${#conf[@]} -lt ${#ch[@]} ] && echo "less than, continue!" && continue 
    [ ${#conf[@]} -gt ${#ch[@]} ] && echo "greater than, break!" && break
    #with current way of generating config, above 2 cases don't happen
    for (( i_cf=0; i_cf<${#conf[@]}; i_cf++ )); do #index config
      echo "${ch[$i_cf]}: ${apps[${ch[$i_cf]}]}:${conf[$i_cf]}"
    done
    #ignore app start order
    #continue with app priority
    while IFS= read -r line_pri; do
      [ -z "$line_pri" ] && break
      echo "priority: $line_pri"
      pri=($line_pri)
      echo "point $point" >> all_config
      list_app="null"
      max_pri=2 # used in comparing the expected and real/observed network behaviour later
      for (( i_pri=0; i_pri<${#pri[@]}; i_pri++ )); do #index priority
        echo "${apps[${ch[$i_pri]}]}:${conf[$i_pri]}:${pri[$i_pri]}:${ts[${ch[$i_pri]}]}" | tee -a all_config
	#loop to next dimension, target switch: already done above
	#now enough to write config file for SDN applications of inner controller in machine con0
	echo "Point $point: Generating config for ${apps[${ch[$i_pri]}]}"
	file=${apps[${ch[$i_pri]}]}_config_global
	echo "${pri[$i_pri]} #priority" > $file
	echo "${ts[${ch[$i_pri]}]} #target switches" >> $file
	echo "${conf[$i_pri]} #app config" >> $file
	echo >> $file
	echo "[global] #generated by the script from outer machine" >> $file
	if [ $max_pri -lt ${pri[$i_pri]} ]; then
	  max_pri=${pri[$i_pri]}
	fi
	
	scp "${apps[${ch[$i_pri]}]}"_config_global con0:"$APPDIR"
    	# adapt the local config file of the control app (CA): each CA has in *massive* directory of con0 the local1/2/3... file, choose one to be the *local*.
    	ssh -n con0 "sh -c 'cd $APPDIR; cp ${apps[${ch[$i_pri]}]}_config_local${conf[$i_pri]} ${apps[${ch[$i_pri]}]}_config_local'"

	if [[ $list_app == "null" ]]; then
          list_app=${apps[${ch[$i_pri]}]}
	else
	  list_app="$list_app ${apps[${ch[$i_pri]}]}"
	fi
	#run controller
	#generate traffic at end-point
	#TODO: loop through end-point traffic profile and end-point combination dimensions
	#dump traffic in involved end-points and routers, observe the path
	#stop end-point, stop controller
	#compare trace files with run in isolation to detect anomalies.

      done
      echo "list_app = $list_app"
      # control the detector_log_filename in the controller according to the experiment point, 
      # these files are later collected in the dataset
      ssh -n con0 "sh -c 'cd $APPDIR; echo detector_log_$point > detector_log_filename'" 
      bash collectdata_controller.bash $list_app
      exit_code=$?
      [ $exit_code -ne 0 ] && echo "Controller is not running, exit code $exit_code" | tee -a conflict.txt && exit 1
      bash collectdata_dataplane.bash $point "${comb[0]}" "${comb[1]}" "$numsw"
      bash collectdata_stop_and_clean.bash "$numsw" "$numep"
      exit_code=$?
      [ $exit_code -ne 0 ] && echo "stop and clean error!, exit code $exit_code" && exit 1

      #################################################################################
      # Now compare the expected and real network behaviour. The criteria include: priority,
      # communication state between end-points, the number of rules in the flow table of the
      # highest priority apps, the link bandwidth. Refer to the document/Cuong's dissertation
      # for much more detail.
      #
      #
      #################################################################################
      # First extract the app(s) with highest priority, which is the $max_pri
      #echo "highest priority:max_pri=$max_pri"
      for (( i_pri=0; i_pri<${#pri[@]}; i_pri++ )); do #index priority
        ########################################################
        # uncomment the next line to compare observed and co-deployed network behaviour from 
        # only control apps of highest priority, else all apps are checked
	      #[ ${pri[$i_pri]} -lt $max_pri ] && continue
        ########################################################
        for i in $list_app; do
          app=$(basename "$i" .py)
          if [[ "$app" != "detector" ]] && [[ "$app" != "routing" ]]
          then
            if [[ ${apps[${ch[$i_pri]}]} == "$app" ]]; then
              tsstr=(${ts[${ch[$i_pri]}]}) # target switch string
              # if the app references any hosts or switches in its config, parse config and add the nodes
              # to the target switches or endpoints where necessary
              hasAssets=$(bash collectdata_checkAppAssets.bash "$app")
              rep=null
              if [[ $hasAssets -gt 0 ]]
              then
                switches=$(bash collectdata_getAppRouterAssets.bash "$app")
                switches=($switches)
                tsstr=("${tsstr[@]}" "${switches[@]}")
                rep=($(bash collectdata_getAppHostAssets.bash "$app"))
              fi
              cookie=$(bash collectdata_getAppCookie.bash "$app")
              # check the delivery state at end-points
              # get any host ips from the app config
              echo "$app"
              if [[ "$rep" == "null" ]]
              then
                echo "No endpoints to check"
              else
                for (( i_rep=0; i_rep<${#rep[@]}; i_rep++ )); do #index of replica
                  i_pc=$(echo "${rep[$i_rep]}" | cut -d'.' -f4) #index of pc: i_pc=3 / i_pc=4
                  echo "i_pc=$i_pc"
                  iso_count=$(ssh -n pc"$i_pc" "sh -c 'grep -c ^connect tmpnc_recv_${app}_${conf[$i_pri]}'") #iso = isolated
                  cdp_count=$(ssh -n pc"$i_pc" "sh -c 'grep -c ^connect tmpnc_recv_$point'") #cdp = co-deployment
                  [ "$iso_count" -ne "$cdp_count" ] && echo "conflict, $app is not fulfilled at end-point for nc test, pc$i_pc, iso=$iso_count, cdp=$cdp_count, applist=$list_app, point=$point" | tee -a $CONFLICT_FILE

                  iso_count=$(ssh -n pc"$i_pc" "sh -c 'grep -c connected tmpiperf_recv_${app}_${conf[$i_pri]}'") #iso = isolated
                  cdp_count=$(ssh -n pc"$i_pc" "sh -c 'grep -c connected tmpiperf_recv_$point'") #cdp = co-deployment
                  [ "$iso_count" -ne "$cdp_count" ] && echo "conflict, $app is not fulfilled at end-point for iperf test, pc$i_pc, iso=$iso_count, cdp=$cdp_count, applist=$list_app, point=$point" | tee -a $CONFLICT_FILE
                done
              fi
              # check rules at target switches, just compare the number of rules installed by eplb
              # if the app config contains switches as assets, these will be added to the target switches and are also checked
              echo "Checking target switches: ${tsstr[@]}"
              for (( i_ts=0; i_ts<${#tsstr[@]}; i_ts++ )); do
              # check rules at target switches, just compare the number of rules installed by pplb4d
                iso_count=$(ssh -n router"${tsstr[$i_ts]}" "sh -c 'grep -c $cookie router${tsstr[$i_ts]}\_dumpflows_${app}_${conf[$i_pri]}'")
                cdp_count=$(ssh -n router"${tsstr[$i_ts]}" "sh -c 'grep -c $cookie router${tsstr[$i_ts]}\_dumpflows_$point'")
                [ "$iso_count" -ne "$cdp_count" ] && echo "conflict, the number of rules at switch ${tsstr[$i_ts]} by app $app differs between isolated and co-deployed run, iso=$iso_count, cdp=$cdp_count, applist=$list_app, point=$point" | tee -a $CONFLICT_FILE
                # check ports' throughput
                # calculate bw when deploying app in isolation, link bw = max link bw when this all was running.
                # Likewise, calculate bw of point, i.e., when apps are deployed together
                ts_i=${tsstr[$i_ts]}
                list_eth=$(ssh -n router"$ts_i" "tcpdump -D | grep -v eth0 | grep eth | sed --expression='s/^[0-9]\+.//g' | cut -c4-5 | xargs") #correct until eth99
                #list ethernet in form, e.g., "1 2 3"
                echo "list_eth = $list_eth"
                for eth in $list_eth; do
                  echo "filename = router"$ts_i"_eth"$eth"_${app}_"${conf[$i_pri]}".txt"
                  tmp=$(ssh -n router$ts_i "bash calculate_max_bw_from_netbps_script.bash router"$ts_i"_eth"$eth"_${app}_"${conf[$i_pri]}".txt")
                  echo "tmp bw = $tmp"
                  [ -z ${iso_bw_r[$ts_i,$eth]} ] && declare -A iso_bw_r[$ts_i,$eth] && iso_bw_r[$ts_i,$eth]=0
		  [[ $(compareV2 ${iso_bw_r[$ts_i,$eth]} $tmp) -eq 1 ]] && iso_bw_r[$ts_i,$eth]=$tmp #isolation bw router iso_bw_r
                  # Now, calculate bw in co-deployment, i.e., at current point.
                  bw_r[$ts_i,$eth]=$(ssh -n router$ts_i "bash calculate_max_bw_from_netbps_script.bash router"$ts_i"_eth"$eth"_"$point".txt")
                  echo "bw when deploying apps in isolation of router[$ts_i,$eth] = ${iso_bw_r[$ts_i,$eth]}"
                  echo "bw when deploying apps together of router[$ts_i,$eth] = ${bw_r[$ts_i,$eth]}"
                  if [[ $(compareV2 0 ${iso_bw_r[$ts_i,$eth]}) -eq 0 ]] && [[ $(compareV2 0 ${bw_r[$ts_i,$eth]}) -eq 1 ]]
                  then
                    echo "Conflict for bw of unused port in isolation=${iso_bw_r[$ts_i,$eth]}, bw in codeployment=${bw_r[$ts_i,$eth]}, applist=$list_app, point=$point,router$ts_i, eth$eth" | tee -a conflict.txt
                  elif [[ $(compareV2 0 ${iso_bw_r[$ts_i,$eth]}) -eq 1 ]] && [[ $(compareV2 0 ${bw_r[$ts_i,$eth]}) -eq 0 ]]
                  then
                    echo "Conflict for bw of used port in isolation=${iso_bw_r[$ts_i,$eth]}, bw in codeployment=${bw_r[$ts_i,$eth]}, applist=$list_app, point=$point,router$ts_i, eth$eth" | tee -a conflict.txt
                  fi 
                  tmp1=$(abs $(bc -l <<< "${iso_bw_r[$ts_i,$eth]} - ${bw_r[$ts_i,$eth]}" ))
                  echo "bw difference = $tmp1"
                  # check if a threshold for checking the bandwidth difference was specified in the experiment model
                  bw_diff_thres=$(grep -c bw_difference_threshold parameter_space.json)
                  if [[ $bw_diff_thres -gt 0 ]]
                  then
                    bw_diff_thres=$(grep bw_difference_threshold parameter_space.json | grep -o "[0-9]*")
		              else
		                bw_diff_thres=5
                  fi
                  echo "Configured threshold for bandwidth difference is $bw_diff_thres"
		              [[ $(compareV2 $tmp1 $bw_diff_thres) -eq 0 ]] && (echo "conflict, bw difference=$tmp1, applist=$list_app, point=$point,router$ts_i, eth$eth" | tee -a conflict.txt) || echo "no problem"
                done
              done
            fi
          fi
        done
      done

:
      (( point++ ))
      sleep 20

    done < "priority${#conf[@]}"

  done < "app_config"

done < "app_choice"

echo Experiment finished at $(date +"%y%m%d_%H%M%S") | tee -a conflict.txt

# store data in the dataset
mkdir -p dataset/"$id"
cp all_config conflict.txt -t dataset/"$id"

echo "Store router*_dumpflows_* from all routers/switches in the dataset"
for i in $(seq 1 "$numsw"); do echo -n "router$i "; ssh -n router$i "sh -c 'tar zcf router$i\_dumpflows.tar.gz router$i\_dumpflows_*'";scp router"$i":router"$i"_dumpflows.tar.gz dataset/"$id"; done

# upload results to remote machine if config file was inserted when topology was generated
mkdir -p sdn_results
cp parameter_space.json -t dataset/"$id"
scp -p con0:"$APPDIR"/detector_log_* dataset/"$id" || echo "No detector log on con0!"
ssh -n con0 "sh -c 'rm /root/massive/detector_log'" || echo "No detector log to delete!"
ssh -F ~/.ssh/sdn_config sdn "mkdir -p sdn_results" || echo "Failed to ssh to remote machine!"
scp -p -F ~/.ssh/sdn_config -r dataset/"$id" sdn:sdn_results || exit 0
rm -r dataset/"$id"
